{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persistence is \"the continuance of an effect after its cause is removed\". In the context of storing data in a computer system, this means that the data survives after the process with which it was created has ended. In other words, for a data store to be considered persistent, it must write to non-volatile storage.\n",
    "\n",
    "In short, storing any data generated by python script to secondary memory is called data persistence.\n",
    "\n",
    "Persisted data can be used again while no persistence data is lost after system shutdown as it is stored on volatile memory, i.e RAM or ROM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish data persistence we use a process called serialization.\n",
    "\n",
    "**Serialization**\n",
    "It is a process to convert a data structure into ad linear form that can be stored or transmitted over a network.\n",
    "\n",
    "In python serialization allows us to take complex object structure and transform it into a stream of bytes that can be save to a disk or sent over a network.\n",
    "\n",
    "Serialization is sometimes also called marshalling.\n",
    "\n",
    "Now to convert these serialized data back to their original data structure we use process called deserialization or unmarshalling.\n",
    "\n",
    "Python has three different module for this purpose:\n",
    "- `pickle`\n",
    "- `marshal`\n",
    "- `json`\n",
    "- `shelve`\n",
    "- Storing to any database (built-in `sqlite3`)\n",
    "\n",
    "`marshall` is oldest module and it exists mainly to read and write the compiled bytecode of python modules, or the `.pyc` files you get when the interpreter imports a python module. So even it can serialize objects it is not recommended.\n",
    "\n",
    "`json` is newest one convenient and widely accepted for data exchange and it serializes objects in human readable form and is light\n",
    "\n",
    "`pickle` serializes objects in binary format thus not human readable, but its faster and works everywhere and allows to custom define objects.\n",
    "\n",
    "**General guidelines for deciding which approach to use:**\n",
    "- Don’t use the marshal module. It’s used mainly by the interpreter, and the official documentation warns that the Python maintainers may modify the format in backward-incompatible ways.\n",
    "\n",
    "- The json module and XML are good choices if you need interoperability with different languages or a human-readable format.\n",
    "\n",
    "- The Python pickle module is a better choice for all the remaining use cases. If you don’t need a human-readable format or a standard interoperable format, or if you need to serialize custom objects, then go with pickle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle implements binary protocols for serializing and deserializing a python object structure.\n",
    "\n",
    "This process of serialization and deserialization is called pickling and unpickling in case we are using `pickle` module.\n",
    "\n",
    "\n",
    "**Data Stream format**\n",
    "- Data format used by `pickle` is python specific.\n",
    "  - Its advantage is that there are no restrictions imposed by external standards such as Json.\n",
    "  - Its disadvantage is that non-python programs may not be able to reconstruct pickled python objects.\n",
    "- By default `pickle` data format use a relatively compact binary representation. We can compress it if we want.\n",
    "- The module `pickletools` contains tools for analyzing data streams generated by `pickle.pickletools` source code has extensive comments about opcodes used by pickle protocols.\n",
    "\n",
    "Importing `pickle` module load three classes `Pickler`, `UnPickler`, `PickleBuffer`.\n",
    "\n",
    "**Methods in Pickle**\n",
    "- `pickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)` Write the pickled representation of the object obj to the open file object file. This is equivalent to `Pickler(file, protocol).dump(obj)`.\n",
    "- `pickle.dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)` Return the pickled representation of the object obj as a bytes object, instead of writing it to a file.\n",
    "- `pickle.load(file, *, fix_imports=True, encoding=\"ASCII\", errors=\"strict\", buffers=None)` read the pickled representation of an object from the open file object and return the reconstituted object hierarchy specified therein. This is equivalent to `Unpickler(file).load()`\n",
    "- `pickle.loads(bytes_object, *, fix_imports=True, encoding=\"ASCII\", errors=\"strict\", buffers=None)` Return the reconstituted object hierarchy of the pickled representation data of an object. data must be a bytes-like object.\n",
    "  \n",
    "\n",
    "**Comparison with Marshal**\n",
    "- `pickle` keeps tracks of the objects it has already serialized, so that later references to the same object won't be serialized again. `marshal` don not do it.\n",
    "- `pickle` can serialize user-defined classes and instances, while `marshal` can't do it.\n",
    "- `marshal` serialization is not guaranteed to be portable across all python versions as its primary job is to support `.pyc` file, while `pickle` provides this guarantee.\n",
    "\n",
    "**Comparison with Json**\n",
    "- `pickle` is binary serialization while `json` is text serialization in `utf-8` format thus human readable.\n",
    "- `pickle` is widely used in python ecosystem only while `json` is interoperable and widely used outside of python ecosystem.\n",
    "- `json` can only serialize a subset of the python built-in types only and no custom classes, while `pickle` can do that.\n",
    "- `json` is far secure than `pickle` as deserializing it doesn't cause any arbitrary code execution.\n",
    "\n",
    "**Note:** \n",
    "- `pickle` module is not secure. \n",
    "- Malicious data can be pickled which will execute arbitrary code during unpickling. \n",
    "- Even pickled data can also be tampered.\n",
    "- Signing data with `hmac` will ensure that it has not been tampered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Alpha:\n",
    "    x = 10\n",
    "    y = True\n",
    "    z = [1, 2, 3]\n",
    "    w = {'a': 1, 'b': 2}\n",
    "    a = (1, 2)\n",
    "\n",
    "obj_alpha = Alpha()\n",
    "\n",
    "pickled_obj = pickle.dumps(obj_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\x05Alpha\\x94\\x93\\x94)\\x81\\x94.'\n"
     ]
    }
   ],
   "source": [
    "print(pickled_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_obj = pickle.loads(pickled_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Alpha object at 0x0000022B55A217C0>\n"
     ]
    }
   ],
   "source": [
    "print(unpickled_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping an object to a file\n",
    "\n",
    "model_pickle = pickle.dump(obj_alpha, open('model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- `dumps` and `loads` writes pickle representation to a file.\n",
    "- `dump` and `load` returns a pickled representation instead of writing to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Marshal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains serialize python objects in binary format which is specific to python and independent to machine architecture.\n",
    "  \n",
    "This is not general persistence module, it mainly exist to support reading and writing the  pseudo-compiled python modules of `.pyc` files. Therefore the python maintainers reserve the right to modify the marshal format in backward incompatible ways should the need arise.\n",
    "\n",
    "All python objects ar not supported by `marshal`, generally onl objects whose values is independent of particular invocation of python can be serialized.\n",
    "\n",
    "**Methods in Marshal**\n",
    "- `marshal.dump(value, file[, version])` write the value on writeable binary file\n",
    "- `marshal.dumps(value[, version])` return the bytes object that would be written to a file by `dump(value, file)`\n",
    "- `marshal.load(file)` read one value from the open file nad return it\n",
    "- `marshal.loads(bytes)` convert the bytes-like-objects to a value\n",
    "- `marshal.version()` indicates the format that the module uses\n",
    "\n",
    "**Note:** \n",
    "- This binary format changes with python versions, this is one of reasons why it is not suggested to use `marshal` for serialization.\n",
    "- `marshal` is not secure against erroneous and maliciously constructed data.\n",
    "- It is not recommended to use and it changes drastically from one version to another, thus officially its not documented well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marshal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marshal.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JavaScript Notation is a light weight data interchange format inspired by JavaScript object literal syntax.\n",
    "\n",
    "\n",
    "`json` module contains all classes and methods required to handle JSON data in python.\n",
    "\n",
    "**Methods in JSON**\n",
    "- `json.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)` serialize python object as a JSON formatted stream\n",
    "  - The json module always produces str objects, not bytes objects. \n",
    "  - If `ensure_ascii` is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped, if false these characters will be output as-is.\n",
    "  - If `check_circular` is false (default: True), then the circular reference check for container types will be skipped and a circular reference will result in a RecursionError (or worse).\n",
    "  - If `allow_nan` is false (default: True), then it will be a ValueError to serialize out of range float values (nan, inf, -inf) in strict compliance of the JSON specification, if  true their JavaScript equivalents (NaN, Infinity, -Infinity) will be used.\n",
    "  - If `sort_keys` is true (default: False), then the output of dictionaries will be sorted by key.\n",
    "  - If `indent` is a non-negative integer or string, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0, negative, or \"\" will only insert newlines. None (the default) selects the most compact representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as \"\\t\"), that string is used to indent each level.\n",
    "  \n",
    "- `json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)` serialize python object as a JSON formatted string, the arguments have same meaning as above\n",
    "  \n",
    "- `json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)` deserialize a JSON stream\n",
    "  - `object_hook` is an optional function that will be called with the result of any object literal decoded (a dict). The return value of object_hook will be used instead of the dict. This feature can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
    "  - `object_pairs_hook` is an optional function that will be called with the result of any object literal decoded with an ordered list of pairs. The return value of object_pairs_hook will be used instead of the dict. This feature can be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority.\n",
    "  - `parse_float`, if specified, will be called with the string of every JSON float to be decoded. By default, this is equivalent to float(num_str). This can be used to use another datatype or parser for JSON floats (e.g. decimal.Decimal).\n",
    "  - `parse_int`, if specified, will be called with the string of every JSON int to be decoded. By default, this is equivalent to int(num_str). This can be used to use another datatype or parser for JSON integers (e.g. float).\n",
    "  - `parse_constant`, if specified, will be called with one of the following strings: '-Infinity', 'Infinity', 'NaN'. This can be used to raise an exception if invalid JSON numbers are encountered.\n",
    "  \n",
    "- `json.loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)` deserialize a JSON string, the arguments have same meaning as above\n",
    "\n",
    "- `json.JSONDecoder.decode(s)` return the python representation of `s` (a JSON string)\n",
    "\n",
    "- `json.JSONDecoder.raw_decode(s)` decode a JSON document from `s`(a JSON string) and return a 2-tuple of the python representation and the index in `s` where the document ended\n",
    "\n",
    "- `json.JSONEncoder.default(o)` this method if implemented in subclass such that it returns a serializable object `o`\n",
    "\n",
    "- `json.JSOEncoder.encode(o)` return a JSON string representation of a python data structure\n",
    "\n",
    "- `json.JSONEncoder.iterencode(o)` encode the given object `o` and yield each string representation as available\n",
    "\n",
    "\n",
    "**Classes in json**\n",
    "- `class json.JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)` Extensible JSON encoder for python data structures\n",
    "  - Supports following objects and types by default:\n",
    "    |JSON|PYTHON|\n",
    "    |--------|---------|\n",
    "    |object|dict|\n",
    "    |array|list, tuple|\n",
    "    |string|str|\n",
    "    |number|int, float|\n",
    "    |true|True|\n",
    "    |false|False|\n",
    "    |null|None|\n",
    "\n",
    "- `class json.JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)` JSON decoder, supports the objects and types as mentioned in above table\n",
    "  \n",
    "\n",
    "**Note:**\n",
    "- JSON data from untrusted source can contain malicious string that may lead decoder to consume considerable CPU and memory resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"streaming API\"]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "io = StringIO()\n",
    "json.dump(['streaming API'], io)\n",
    "io.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ['baz', None, 1.0, 2]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['streaming API']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "io = StringIO('[\"streaming API\"]')\n",
    "json.load(io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[2.0', ', 1.0', ']']\n"
     ]
    }
   ],
   "source": [
    "# Extending JSON Encoder\n",
    "class ComplexEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, complex):\n",
    "            return [obj.real, obj.imag]\n",
    "        # Let the base class default method raise the TypeError\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "json.dumps(2 + 1j, cls=ComplexEncoder)\n",
    "ComplexEncoder().encode(2 + 1j)\n",
    "l = list(ComplexEncoder().iterencode(2 + 1j))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default(self, o):\n",
    "   try:\n",
    "       iterable = iter(o)\n",
    "   except TypeError:\n",
    "       pass\n",
    "   else:\n",
    "       return list(iterable)\n",
    "   # Let the base class default method raise the TypeError\n",
    "   return json.JSONEncoder.default(self, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"foo\": [\"bar\", \"baz\"]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[2', ', 4', ', 6', ']']\n"
     ]
    }
   ],
   "source": [
    "l= [2,4,6]\n",
    "e = []\n",
    "for chunk in json.JSONEncoder().iterencode(l):\n",
    "    e.append(chunk)\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"shelf\" is a persistent dictionary like object. Where the values of dictionary are python objects and keys are arbitrary strings.\n",
    "\n",
    "\n",
    "`shelve` module contains all relevant code related to shelf.\n",
    "\n",
    "**Methods in Shelve**\n",
    "- `shelve.open(filename, flag='c', protocol=None, writeback=False)` open a persistent dictionary.\n",
    "  - `filename` specified is the base filename for underlying database\n",
    "  - It need to be closed after opening and can be closed and opened at same time using `open()` much like how file IO operations syntax is\n",
    "- `shelf.sync()` write back all entries in teh cache if the shelf was opened with `writeback` set to True, this is called automatically when shelf closed with `clOse()`\n",
    "- `shelf.close()` synchronize and close the persistent shelf object.\n",
    "\n",
    "**Classes in Shelve**\n",
    "- `class shelve.Shelf(dict, protocol=None, writeback=False, keyencoding='utf-8')` subclass of `collections.abc.MutableMapping` which stores pickled values in the dict object.    \n",
    "- `class shelve.BsdDbShelf(dict, protocol=None, writeback=False, keyencoding='utf-8')` subclass of Shelf which exposes `first(), next(), previous(), last() and set_location()` which are available in the third-party bsddb module from pybsddb but not in other database modules. \n",
    "  \n",
    "- `class shelve.DbfilenameShelf(filename, flag='c', protocol=None, writeback=False)` subclass of Shelf which accepts a filename instead of a dict-like object. The underlying file will be opened using dbm.open(). By default, the file will be created and opened for both read and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
