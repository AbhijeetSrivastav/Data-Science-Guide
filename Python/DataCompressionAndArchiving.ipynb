{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compression and Archiving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Compression**\n",
    "- It is the process of reducing the size of a file or data to save storage space and improve transmission efficiency.\n",
    "\n",
    "**Types of Data Compression**\n",
    "- Lossless Compression: \n",
    "  - In this method, data is compressed without any loss of information. The original data can be perfectly reconstructed from the compressed version.\n",
    "  - Common lossless compression methods include Huffman coding, Run-Length Encoding (RLE), Lempel-Ziv-Welch (LZW), and Burrows-Wheeler Transform (BWT).\n",
    "  - Lossless compression is ideal for text files, databases, and program files where preserving the exact data is critical.\n",
    "  \n",
    "- Lossy Compression: \n",
    "  - In this method, data is compressed with some loss of information. The reconstructed data might not be identical to the original, but the loss is often imperceptible, like in audio and image compression.\n",
    "  - It is commonly used in multimedia applications, such as image, audio, and video compression, where minor quality loss is acceptable to achieve significant file size reduction.\n",
    "  - Popular lossy compression methods include JPEG (for images), MP3 (for audio), and H.264 (for video).\n",
    "  \n",
    "\n",
    "The choice between lossless and lossy compression depends on the specific use case and the importance of preserving the original data fidelity. Lossless compression is preferred when data integrity is critical, while lossy compression is more suitable for cases where reducing file size is the primary concern and minor quality loss is acceptable.\n",
    "\n",
    "\n",
    "**Data Archiving**\n",
    "- It is the process of storing data for long-term preservation and easy retrieval, typically to free up space on active storage systems.\n",
    "- Archiving helps maintain historical records, compliance with regulations, and data retention policies.\n",
    "- Archiving can involve segmenting data based on its relevance and importance, moving less frequently accessed data to archival storage.\n",
    "- Data is usually stored in archival formats that ensure long-term preservation, often using open standards to avoid proprietary dependencies.\n",
    "\n",
    "\n",
    "**Data Compression vs Data Archiving**\n",
    "- Data compression focuses on reducing file sizes to optimize storage and data transmission, \n",
    "- while data archiving aims to preserve and manage data for long-term accessibility and regulatory compliance. \n",
    "- Both techniques are essential for efficient data management and play complementary roles in ensuring data is stored, organized, and made available as needed.\n",
    "\n",
    "**Python Libraries for Data Compression and Archiving**\n",
    "- `zlib` this library allows to do compressions \n",
    "- `gzip` This library allows you to work with gzip-compressed files using both file-like objects and in-memory data.\n",
    "- `bz2` It provides functions to compress and decompress data using the bzip2 compression algorithm.\n",
    "- `lzma` This library offers support for the LZMA and XZ compression formats.\n",
    "- `zipfile` It enables you to create, read, and extract ZIP archives.\n",
    "- `tarfile` This library allows you to create, read, and extract tar archives, which can then be optionally compressed using other compression libraries like gzip or bzip2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zlib` module is used for compressing and decompressing files with `.gz` extensions. While `gzip` module is used to read and write `.gz` files. \n",
    "\n",
    "**Methods in Zlib**\n",
    "- `zlib.adler32(data[, value])` it computes an Adler-32 checksum of data, the result is an unsigned 32-bit integer. If value is present, it is used as the starting value of the checksum; otherwise, a default value of 1 is used.\n",
    "  \n",
    "- `zlib.compress(data, /, level=- 1, wbits=MAX_WBITS)` it compresses the bytes in data, returning a bytes object containing compressed data. \n",
    "  - `level` is an integer from 0 to 9 or -1 controlling the level of compression; 1 (Z_BEST_SPEED) is fastest and produces the least compression, 9 (Z_BEST_COMPRESSION) is slowest and produces the most. 0 (Z_NO_COMPRESSION) is no compression. The default value is -1 (Z_DEFAULT_COMPRESSION). Z_DEFAULT_COMPRESSION represents a default compromise between speed and compression (currently equivalent to level 6).\n",
    "  - `wbits` argument controls the size of the history buffer (or the “window size”) used when compressing data, and whether a header and trailer is included in the output. It can take several ranges of values, defaulting to 15 (MAX_WBITS):\n",
    "\n",
    "- `zlib.compressobj(level=-1, method=DEFLATED, wbits=MAX_WBITS, memLevel=DEF_MEM_LEVEL, strategy=Z_DEFAULT_STRATEGY[, zdict])` returns a compression object, to be used for compressing data streams that won’t fit into memory at once.\n",
    "  - `level` is the compression level – an integer from 0 to 9 or -1. A value of 1 (Z_BEST_SPEED) is fastest and produces the least compression, while a value of 9 (Z_BEST_COMPRESSION) is slowest and produces the most. 0 (Z_NO_COMPRESSION) is no compression. The default value is -1 (Z_DEFAULT_COMPRESSION). Z_DEFAULT_COMPRESSION represents a default compromise between speed and compression (currently equivalent to level 6).\n",
    "  - `method` is the compression algorithm. \n",
    "  - `wbits` same as described above\n",
    "  - `memLevel` controls the amount of memory used for the internal compression state, values range from 1 to 9. Higher values use more memory, but are faster and produce smaller output.\n",
    "  - `strategy` is used to tune the compression algorithm. Possible values are Z_DEFAULT_STRATEGY, Z_FILTERED, Z_HUFFMAN_ONLY, Z_RLE and Z_FIXED.\n",
    "  - `zdict` is a predefined compression dictionary. This is a sequence of bytes (such as a bytes object) containing subsequences that are expected to occur frequently in the data that is to be compressed. Those subsequences that are expected to be most common should come at the end of the dictionary.\n",
    "\n",
    "- `zlib.crc32(data[, value])` computes a CRC (Cyclic Redundancy Check) checksum of data. The result is an unsigned 32-bit integer. If value is present, it is used as the starting value of the checksum; otherwise, a default value of 0 is used. Passing in value allows computing a running checksum over the concatenation of several inputs. \n",
    "  \n",
    "- `zlib.decompress(data, /, wbits=MAX_WBITS, bufsize=DEF_BUF_SIZE)`\n",
    "decompresses the bytes in data, returning a bytes object containing the uncompressed data. \n",
    "  - If `bufsize` is given, it is used as the initial size of the output buffer. Raises the error exception if any error occurs.\n",
    "\n",
    "- `zlib.decompressobj(wbits=MAX_WBITS[, zdict])` returns a decompression object, to be used for decompressing data streams that won’t fit into memory at once.\n",
    "\n",
    "- `Compress.compress(data)` compress data, returning a bytes object containing compressed data for at least part of the data in data. This data should be concatenated to the output produced by any preceding calls to the compress() method. Some input may be kept in internal buffers for later processing.\n",
    "\n",
    "- `Compress.flush([mode])` all pending input is processed, and a bytes object containing the remaining compressed output is returned. mode can be selected from the constants Z_NO_FLUSH, Z_PARTIAL_FLUSH, Z_SYNC_FLUSH, Z_FULL_FLUSH, Z_BLOCK or Z_FINISH, defaulting to Z_FINISH. Except Z_FINISH, all constants allow compressing further bytestrings of data, while Z_FINISH finishes the compressed stream and prevents compressing any more data. After calling flush() with mode set to Z_FINISH, the compress() method cannot be called again; the only realistic action is to delete the object.\n",
    "\n",
    "- `Compress.copy()` returns a copy of the compression object. This can be used to efficiently compress a set of data that share a common initial prefix.\n",
    "\n",
    "- `Decompress.unused_data` a bytes object which contains any bytes past the end of the compressed data. That is, this remains b\"\" until the last byte that contains compression data is available. If the whole bytestring turned out to contain compressed data, this is b\"\", an empty bytes object.\n",
    "\n",
    "- `Decompress.unconsumed_tail` a bytes object that contains any data that was not consumed by the last decompress() call because it exceeded the limit for the uncompressed data buffer. This data has not yet been seen by the zlib machinery, so you must feed it (possibly with further data concatenated to it) back to a subsequent decompress() method call in order to get correct output.\n",
    "\n",
    "- `Decompress.eof` boolean indicating whether the end of the compressed data stream has been reached.\n",
    "\n",
    "- `Decompress.decompress(data, max_length=0)` decompress data, returning a bytes object containing the uncompressed data corresponding to at least part of the data in string. This data should be concatenated to the output produced by any preceding calls to the decompress() method. Some of the input data may be preserved in internal buffers for later processing.\n",
    "\n",
    "- `Decompress.flush([length])` all pending input is processed, and a bytes object containing the remaining uncompressed output is returned. After calling flush(), the decompress() method cannot be called again; the only realistic action is to delete the object.\n",
    "\n",
    "- `Decompress.copy()` returns a copy of the decompression object. This can be used to save the state of the decompressor midway through the data stream in order to speed up random seeks into the stream at a future point.\n",
    "\n",
    "- `zlib.ZLIB_VERSION` returns version of zlib used in building the module\n",
    "\n",
    "- `zlib.ZLIB_RUNTIME_VERSION` returns version of zlib loaded by interpreter\n",
    "\n",
    "**Note:**\n",
    "- Zlib has a official documentation page - [Zlib](https://www.zlib.net/)\n",
    "- Zlib Architecture manual - [Manual](https://www.zlib.net/manual.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello world'\n",
      "b'x^\\xf3H\\xcd\\xc9\\xc9W(\\xcf/\\xcaI\\x01\\x00\\x18\\xab\\x04='\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "import binascii\n",
    "\n",
    "\n",
    "data = b'Hello world'\n",
    "\n",
    "compressed_data = zlib.compress(data, 2)\n",
    "\n",
    "print(data)\n",
    "print(compressed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gzip` module used for compression and decompression.\n",
    "\n",
    "`gzip` has `GzipFile` class which is used to read and write gzip-format files (`.gz`).\n",
    "\n",
    "**Methods in Gzip**\n",
    "- `gzip.open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)` open a gzip-compressed file in binary or text mode, returning a file object.\n",
    "  - `filename`  can be an actual filename or an existing file object to read from or write to.\n",
    "  - `mode` can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x' or 'xb' for binary mode, or 'rt', 'at', 'wt', or 'xt' for text mode.(default is 'rb').\n",
    "  - `compresslevel` is an integer from 0 to 9, as for the GzipFile constructor.\n",
    "\n",
    "**Classes in Gzip**\n",
    "`class gzip.GzipFile(filename=None, mode=None, compresslevel=9, fileobj=None, mtime=None)` constructor for the GzipFile class \n",
    "  - `fileobj` is not None, the filename is only used to be included in the gzip file header, which may include the original filename of the uncompressed file. It defaults to the filename of fileobj, if discernible; otherwise, it defaults to the empty string, and in this case the original filename is not included in the header.\n",
    "  - `mode` same as above\n",
    "  - `compresslevel` is an integer from 0 to 9 controlling the level of compression; 1 is fastest and produces the least compression, and 9 is slowest and produces the most compression. 0 is no compression. The default is 9.\n",
    "  - `mtime` is an optional numeric timestamp to be written to the last modification time field in the stream when compressing. It should only be provided in compression mode. If omitted or None, the current time is used. \n",
    "  - `peek(n)` read n uncompressed bytes without advancing the file position. At most one single read on the compressed stream is done to satisfy the call. The number of bytes returned may be more or less than requested.\n",
    "  - `name` the path to the gzip file on disk, as a str or bytes. Equivalent to the output of os.fspath() on the original input path, with no other normalization, resolution or expansion.\n",
    "\n",
    "- `gzip.compress(data, compresslevel=9, *, mtime=None)`\n",
    "Compress the data, returning a bytes object containing the compressed data. compresslevel and mtime have the same meaning as in the GzipFile constructor above. When mtime is set to 0, this function is equivalent to zlib.compress() with wbits set to 31. The zlib function is faster.\n",
    "\n",
    "- `gzip.decompress(data)` decompress the data, returning a bytes object containing the uncompressed data. This function is capable of decompressing multi-member gzip data (multiple gzip blocks concatenated together). When the data is certain to contain only one member the zlib.decompress() function with wbits set to 31 is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading compressed file\n",
    "import gzip\n",
    "with gzip.open('/home/joe/file.txt.gz', 'rb') as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating compressed GZIP file\n",
    "import gzip\n",
    "content = b\"Lots of content here\"\n",
    "with gzip.open('/home/joe/file.txt.gz', 'wb') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating compressed GZIP file\n",
    "import gzip\n",
    "import shutil\n",
    "with open('/home/joe/file.txt', 'rb') as f_in:\n",
    "    with gzip.open('/home/joe/file.txt.gz', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gzip compress a binary string\n",
    "import gzip\n",
    "s_in = b\"Lots of content here\"\n",
    "s_out = gzip.compress(s_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BZ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bz2` uses bzip2 compression algorithm.\n",
    "\n",
    "**Classes in Bz2**\n",
    "- `class bz2.BZ2File(filename, mode='r', *, compresslevel=9)` opens a bzip2-compressed file in binary mode.\n",
    "  - `filename` should be str or bytes object or file object\n",
    "  - `mode` can be  'rb', 'wb', 'xb', 'ab', 'r' (default), 'w'\n",
    "\n",
    "- - `class bz2.BZ2Compressor(compresslevel=9)` create a new compressor object. This object may be used to compress data incrementally. \n",
    "  -  For one-shot compression, use the `compress()` function instead.\n",
    "  - `compresslevel`, an integer between 1 and 9. The default is 9.\n",
    "\n",
    "- `class bz2.BZ2Decompressor` create a new decompressor object. This object may be used to decompress data incrementally. \n",
    "  - For one-shot compression, use the `decompress()` function instead.\n",
    "\n",
    "**Methods in Bz2**\n",
    "- `bz2.open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)` open a bzip2 compressed file\n",
    "- `bz2.compress(data, compresslevel=9)` compress data as bytes like object (one shot compression)\n",
    "- `bz2.decompress(data)` decompress data as bytes like object (one shot decompression)\n",
    "- `bz2.BZ2File.peek([n])` return buffered data without advancing the file position\n",
    "- `bz2.BZ2Compressor.compress(data)` returns chunk of compressed data if possible else an empty string\n",
    "- `bz2.BZ2Compressor.flush()` finish the compression process and returns the compressed data in internal buffers. compressor object cant be used after calling this method\n",
    "- `bz2.BZ2Decompressor.decompress(data, maxlength=-1)` decompress the data and return uncompressed data as bytes\n",
    "  - `max_length` specifies at most bytes to be decompressed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Shot compression and decompression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "data = b\"\"\"Iron Man\"\"\"\n",
    "\n",
    "c = bz2.compress(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Compression Ratio:0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Data Compression Ratio:' + str(len(data) / len(c)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = bz2.decompress(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying decompressed data same as original data or not\n",
    "data == d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lzma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lzma` module uses LZMA compression algorithm.\n",
    "\n",
    "It uses `.xz` and `.lzma` file extensions.\n",
    "\n",
    "**Classes in Lzma**\n",
    "- `class lzma.LZMAFile(filename=None, mode='r', *, format=None, check=- 1, preset=None, filters=None)` open ana LZMA compressed file in binary mode.\n",
    "    - An LZMAFile can wrap an alread open file object, or operate directly on named file.\n",
    "    - `filename` specifies either the file object to wrap, or the name of the file to open.\n",
    "    - `mode` can be either `r` (default), `w`, `x`, `a`, `rb`, `wb` and `ab` \n",
    "    - `format` specifies what container format should be used, possible values are:\n",
    "      - `FORMAT_XZ` its the default, the `.xz` container format\n",
    "      - `FORMAT_ALONE` the legacy `.lzma` container format\n",
    "      - `FORMAT_RAW` a raw data stream, not using any container format\n",
    "    - `check` specifies the type of integrity check to include in the compressed data, its possible values are:\n",
    "      - `CHECK_NONE` No integrity check. This is the default (and the only acceptable value) for `FORMAT_ALONE` and `FORMAT_RAW`.\n",
    "      - `CHECK_CRC32` 32-bit Cyclic Redundancy Check.\n",
    "      - `CHECK_CRC64` 64-bit Cyclic Redundancy Check. This is the default for `FORMAT_XZ`.\n",
    "      - `CHECK_SHA256` 256-bit Secure Hash Algorithm.\n",
    "    - `preset` is an integer in range of  0 to 9 , if specified higher it is smaller the output and vice versa also higher it is slower the compression will be\n",
    "    - `filter` specifies a filter chain specifier\n",
    "\n",
    "- `class lzma.LZMACompressor(format=FORMAT_XZ, check=- 1, preset=None, filters=None)` create a compressor object which is used to compress data incrementally\n",
    "  - To compress data in a single chunk `compress()` function is used\n",
    "  - Arguments have same meaning as specified above\n",
    "- \n",
    "- `class lzma.LZMADecompressor(format=FORMAT_AUTO, memlimit=None, filters=None)` create a decompressor object which is used to decompress data incrementally\n",
    "  - To decompress data in a single chunk `decompress()` function is used\n",
    "  - Arguments have same meaning as specified above\n",
    "  - `memlimit` specifies a limit in bytes on the amount of memory that decompressor can use\n",
    "\n",
    "**Methods in Lzma**\n",
    "- `lzma.open(filename, mode='rb', *, format=None, check=- 1, preset=None, filters=None, encoding=None, errors=None, newline=None)` open an LZMA compressed file in binary or text mode, returning a file object\n",
    "- `lzma.compress(data, format=FORMAT_XZ, check=- 1, preset=None, filters=None)` Compress data, returning the compressed data as a bytes object.\n",
    "- `lzma.decompress(data, format=FORMAT_AUTO, memlimit=None, filters=None)` decompress data , returning the uncompressed data as a bytes object.\n",
    "- `lzma.is_check_supported(check)` return True if the given integrity check is supported on this system\n",
    "- `lzma.LZMAFile.peek(size=-1)` return buffered data without advancing the file position\n",
    "- `lzma.LZMACompressor.compress(data)` compress data, returning a bytes object containing compressed data for at least part of the input. Some of data may be buffered internally for use in later calls of `compress()` and `flush()`\n",
    "- `lzma.LZMACompressor.flush()` finish the compression process, returning a bytes object containing any data stored in compressor's internal buffers\n",
    "- `lzma.LZMADecompressor.decompress(data, max_length=-1)` decompress data, returning uncompressed data as bytes. Some of data may be buffered internally, for use in later calls to `decompress()`\n",
    "  - `max_length` if non-negative, returns at most `max_length` bytes of decompressed data\n",
    "\n",
    "**Attributes in Lzma**\n",
    "- `lzma.LZMADecompressor.check` the id of the integrity check used by the input stream\n",
    "- `lzma.LZMADecompressor.eof` True if the end-of-stream marker has been reached\n",
    "- `lzma.LZMADecompressor.unused_data` data found after the end of the compressed stream, before the end of the stream it will be `b\"\"`\n",
    "- `lzma.LZMADecompressor.needs_input` False if the `decompress()` method can provide more decompressed data before requiring new uncompressed input\n",
    "\n",
    "**Note:** For custom filter chain creation refer documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a compressed file at once\n",
    "\n",
    "import lzma\n",
    "\n",
    "with lzma.open(\"file.xz\") as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressing a file at once\n",
    "\n",
    "import lzma\n",
    "data = b\"Optimus Prime\"\n",
    "with lzma.open(\"file.xz\", \"w\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xfd7zXZ\\x00\\x00\\x04\\xe6\\xd6\\xb4F\\x02\\x00!\\x01\\x16\\x00\\x00\\x00t/\\xe5\\xa3\\x01\\x00\\rI\\nam\\nIron man\\n\\x00\\x00\\x00\\x9f\\xc2}g\\x97\\xd3\\xd6V\\x00\\x01&\\x0e\\x08\\x1b\\xe0\\x04\\x1f\\xb6\\xf3}\\x01\\x00\\x00\\x00\\x00\\x04YZ'\n"
     ]
    }
   ],
   "source": [
    "# Iterative compression\n",
    "\n",
    "import lzma\n",
    "\n",
    "lzc = lzma.LZMACompressor()\n",
    "\n",
    "out1 = lzc.compress(b\"I\\n\")\n",
    "out2 = lzc.compress(b\"am\\n\")\n",
    "out3 = lzc.compress(b\"Iron man\\n\")\n",
    "\n",
    "out4 = lzc.flush()\n",
    "\n",
    "final_output = b\"\".join([out1, out2, out3, out4])\n",
    "\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing compressed data to an already-open file\n",
    "\n",
    "import lzma\n",
    "\n",
    "with open(\"file.xz\", \"wb\") as f:\n",
    "    f.write(b\"This data will not be compressed\\n\")\n",
    "    with lzma.open(f, \"w\") as lzf:\n",
    "        lzf.write(b\"This *will* be compressed\\n\")\n",
    "    f.write(b\"Not compressed\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a compressed file using a custom filter chain\n",
    "\n",
    "import lzma\n",
    "\n",
    "my_filters = [\n",
    "    {\"id\": lzma.FILTER_DELTA, \"dist\": 5},\n",
    "    {\"id\": lzma.FILTER_LZMA2, \"preset\": 7 | lzma.PRESET_EXTREME},\n",
    "]\n",
    "\n",
    "with lzma.open(\"file.xz\", \"w\", filters=my_filters) as f:\n",
    "    f.write(b\"blah blah blah\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
